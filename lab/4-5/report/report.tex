\documentclass[a4paper,10pt]{article}
\usepackage{fullpage}
\usepackage{times}
\usepackage{listings}
\usepackage{xparse}
\usepackage{hyperref}
\usepackage[a4paper, margin=1in]{geometry}

\usepackage{graphicx}
\graphicspath{ {./images/} }

\usepackage{subfig}
\usepackage[
backend=biber,
style=ieee,
sorting=ynt
]{biblatex}

\addbibresource{references.bib}
 
\usepackage{xcolor}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}
\NewDocumentCommand{\codeword}{v}{%
\texttt{{#1}}%
}




\begin{document}

\title{L41: Lab 3 - The TCP State Machine, Latency, and Bandwidth}
\author{Nicolò Mazzucato \textless{}nm712\textgreater{}}
\date{\today}

\maketitle

\thispagestyle{empty}

\begin{abstract}



\end{abstract}

\clearpage

\setcounter{page}{1}

\section{Introduction}

\section{Experimental setup and methodology}

\subsection{Hardware setup}

For the experiment, it is used the BeagleBone Black board with an open-source FreeBSD\cite{mckusick_design_2014} 11.0 operating system’s ARMv7 port. This board has the following characteristics:
\begin{itemize}
    \item 512MB DDR3 RAM
    \item 4GB 8-bit eMMC on-board flash storage
    \item AM335x 1GHz ARM® Cortex-A8 - Single core 32-bit processor\cite{noauthor_am3358_nodate}
    \begin{itemize}
        \item Independent 32KB L1 instructions and data cache
        \item Shared L2 cache (256KB)
        \item 64 bytes cache lines
    \end{itemize}
\end{itemize}

The board mounts an SD card. However, it is not relevant for the test, as the benchmark is in-memory.

\subsection{Test program}

The benchmark consists of a program able to create two ends of an IPC object using different methodologies (pipes or sockets). The actors of the communication, in our case, are two threads: one that sends data, and the other that receives it. It is possible to set the buffer size for each write request, while the total size of the data sent is constant.


\subsection{Methodology}


In the experimental setup, the size of the total data sent by IPC is kept constant at 16MB. Those data are sent in chunks of different size. The total IPC size must be a multiple of buffer size. We refer to the size of those chunks only as \textit{buffer size}.
The benchmark points three IPC modes: 
\begin{itemize}
    \item \codeword{pipes}, created with the \codeword{pipe()} function.
    \item \codeword{sockets}, created with the \codeword{socketpair()} function.
    \item \codeword{sockets} with the two options \codeword{SO_SNDBUF} and \codeword{SO_RCVBUF} set. Those options adjust the kernel buffer used to send and receive. In our particular case, the maximum buffer size is set trough the sysctl variable \codeword{kern.ipc.maxsockbuf} in a way to always have enough space to match the buffersize set in the user-space benchmark.
\end{itemize}

The performance measurement is possible in several ways. Since our focus is only on the IPC transfer loop, we would skip measuring other non-related parts of the program. The options are:
\begin{itemize}
    \item \codeword{time} utility. However, this does not provide high precision and measures the entire program execution
    \item Benchmark output in verbose mode. The benchmark has an option to output to stdout additional information, such as the time measured between the beginning and the end of the IPC loop.
    \item DTrace. To have an even finer-grained time measure, we can instrument the probe fired at the return of the syscall used to get the time (called before the IPC loop), and the entry of the same function (called after the IPC loop)
\end{itemize}
The choice falls on DTrace for most performance measurements, and on the benchmark output for evaluating the probe effect of DTrace. 
To further investigate the causes of the inflexion points in the performance graph, several other statistics are gathered both from the kernel and micro-architectural point of view.

Probe effect evaluation uses the difference between the run-time with and without DTrace running, from the benchmark output.

All the benchmark runs are executed 11 times for each parameter value, and the first one is dropped. In each graph, it is possible to see the error as a vertical line. However, in almost all cases, this error is negligible, highlighting a controlled benchmarking environment. The value on the graph is the median of the 10 measurements.

We used various DTrace provider in the investigation. The \codeword{profile} provider made possible to understand where most of the time was spent, analyzing the frequency of each \codeword{stack()}. It made possible to identify where data were copied, and create figure \ref{fig:uiomove}. However, due to the board limitations, the profiling frequency was very limited, always below 30Hz. The Function Boundary Provider made possible to visualize the entire execution in Perfetto\cite{noauthor_perfetto_nodate}. The \codeword{sched} provider allowed us to investigate sleeps and wake-ups events.

In addition to kernel tracing, we also make micro-architectural considerations using performance monitoring counters (PMC). Those are low-level processor facilities that allow the programmer to get data about transparent details such as instruction count memory reads and writes, and various cache misses. Particular importance is given to AXI transactions, that are memory accesses against DRAM that causes particular slow down. Those transactions are more frequent when L1 and L2 caches are not enough.
Finally, the effect of PMCs monitoring overhead is evaluated with a comparison to the baseline.


\subsection{Limitations}

During the tracing, several other processes were running, and this might have influenced the results. In particular:
\begin{itemize}
    \item One ssh session
    \item A Jupyter notebook
\end{itemize}

However, the background situation was the same for all the benchmarks, and each measurement is executed eleven times, discarding the first one. The test is focused on the statically linked binary version, so we neglect the dynamically linked one.




\section{Results and discussion}





\subsection{Sockets}


\subsection{Read/write behaviour}


\section{Probe effect}

\section{Conclusions}

\newpage

\section{References}

\printbibliography

\section{Appendices}


\end{document}
